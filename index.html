<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Hide your signer: a Privacy-aware Photorealistic Digital Signer Avatar through Latent Diffusion Model">
  <meta name="keywords" content="Gaussian Avatars, Monocular Avatar Reconstruction, Multi-view Diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hide your signer: a Privacy-aware Photorealistic Digital Signer Avatar through Latent Diffusion Model</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Hide your signer: a Privacy-aware Photorealistic Digital Signer Avatar through Latent Diffusion Model</h1>
          <div style="text-align: center; color: #6a0dad; font-size: 1.2em; margin-top: 10px;">
            Submission ID: 1062
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="teaser_model.png" alt="Teaser Image" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        <b>Privacy-aware Photorealistic Digital Signer Avatar.</b> Given a reference image — synthetic or real — and a target sequence of signing keypoints, our model uses a latent diffusion framework to animate the reference to closely follow the keypoint-driven motion.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="container is-max-desktop">
      <div class="column is-full-width">
        <h2 class="title has-text-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the democratisation of social media use, the deaf community faces a growing challenge: protecting the privacy of sign language 
            users in shared content. Early sign language synthesis models, which often produce videos that resemble specific individuals, 
            raise concerns about identity disclosure. However, current state-of-the-art solutions often degrade visual quality or fail to 
            properly model important attributes such as mouthing. To this end, we propose a novel approach that leverages a Latent Diffusion 
            Model (LDM) to synthesise photorealistic digital signer avatars from a generated reference image. We propose a novel sign feature 
            aggregation module that explicitly models the non-manual (<i>e.g.</i>, face) features and the manual (<i>e.g.</i>, hands) features. 
            We show that our proposed module ensures the preservation of the linguistic content while seamlessly utilising the reference image. 
            Extensive experiments on YouTube-SL-25 sign language dataset show that our pipeline achieves superior visual quality compared to 
            state-of-the-art methods, with significant improvements in perceptual metrics such as PSNR and SSIM. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>

<section class="section">
  <!-- Method Overview -->
  <div class="container is-max-desktop">
    <div class="column is-full-width">
      <h2 class="title has-text-centered">Method Overview</h2>
      <img src="overview.png" style="width:100%; margin-right:auto; margin-left:auto; margin-top:auto;">
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
      <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
      <div class="content has-text-justified">
        <p>
          Given a sequence of video frames \(\mathcal{V} = \{ \mathbf{V}_i \}\) of a sign language, our goal is to synthesise an anonymised sequence \(\mathcal{O} = \{ \mathbf{O}_i \}\) that preserves the manual and non-manual linguistic features while hiding the identity of the signer. 
          Our novel feature aggregation module, \(\Psi_{\text{motion}}\), uses multi-scale dilated convolutions with dilation rates \(d \in \{1, 2, 4\}\) to fuse fine-grained non-manual details 
          (e.g., facial expressions) and coarse manual gestures (e.g., hand movements) into a unified representation. 
          The LDM generates each frame \(\mathbf{O}_i\) through an iterative denoising process in the latent space guided by the aggregated features of \(\Psi_{\text{motion}}\).
        </p>
      </div>
    </div>
  </div>
  <!--/ Method Overview -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title has-text-centered" style="margin-top: 2.5rem;">
      Comparisons against Baselines (DSGS)
    </h2>
    <div style="overflow:hidden;">
      <div class="container">
        <div id="post_images" class="carousel">
          <div class="item-1">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/3002_01.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-2">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/3013_01.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-3">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/3054_01.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-4">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/3073_01.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-5">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/4332_01.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-6">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/DSGS/4348_01.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          Compared to state-of-the-art methods, our approach reconstructs unseen side facial regions in the inputs and consistently produces more favorable and consistent renderings from hold-out views.
        </p>
      </div>
    </div>


    <div class="container is-max-desktop">
    <h2 class="title has-text-centered" style="margin-top: 1.5rem;">
      Comparisons against Baselines (BSL)
    </h2>
    <div style="overflow:hidden;">
      <div class="container">
        <div id="post_images" class="carousel">
          <div class="item-1">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/BSL/HALFWAY.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-2">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/BSL/LEFT-OVER.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-3">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/BSL/PROVIDE-ME.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-4">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/BSL/REVEAL.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-5">
            <video poster="" autoplay="" muted loop="" style="pointer-events: none; width:100%;">
              <source src="./static/videos/BSL/SUPERVISION.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          Compared to state-of-the-art methods, our approach reconstructs unseen side facial regions in the inputs and consistently produces more favorable and consistent renderings from hold-out views.
        </p>
      </div>
    </div>
    
    <h2 class="title has-text-centered" style="margin-top: 1.5rem;">
      Adaptablity to any sign language
    </h2>
    <div style="overflow:hidden;">
      <div class="container">
        <div id="post_images" class="carousel">
          <div class="item-1">
            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width:100%;">
              <source src="./static/videos/more_videos/000000.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-2">
            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width:100%;">
              <source src="./static/videos/more_videos/3013_02.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item-3">
            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width:100%;">
              <source src="./static/videos/more_videos/rachel_OPHTHAMOLOGIST.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div class="content has-text-justified">
        <p>
          <b>Our model can work with any sign language. The first two examples shown are from Swiss-German Sign Language (DSGS) and the last is British Sign Language
        (BSL).</b>
        </p>
      </div>
    </div>

    <h2 class="title has-text-centered" style="margin-top: 1.5rem;">
      Sample diversity
    </h2>
    <div style="overflow:hidden;">
      <div class="container">
        <img
          id="ablation"
          src="teaser-diversity.png"
          alt="Ablation Studies teaser diversity"
          height="100%"
          style="display: block; margin: 0 auto;"
        />
        <div class="content has-text-justified">
          <p>
            <b>Our model can easily adapt to diverse images within the same pose sequence.</b>
          </p>
        </div>
      </div>
    </div>

    <h2 class="title has-text-centered" style="margin-top: 1.5rem;">
      User study
    </h2>
    <div style="overflow:hidden;">
      <div class="container">
        <img src="user_study.png" alt="User Study Results" style="width:100%; height:auto;" />
        <div class="content has-text-justified">
          <p>
            Given a single image as input, <b>our Multi-view Head Latent Diffusion</b> can generate identity-preserved, and view-consistent multi-view portrait images. 
          </p>
        </div>
      </div>
    </div>

    <script>
      bulmaCarousel.attach('#post_images', {
        slidesToScroll: 1,
        slidesToShow: 1,
        loop: true,
      });
    </script>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{anonymous1062,
      title={Hide your signer: a Privacy-aware Photorealistic Digital Signer Avatar
through Latent Diffusion Model},
      author={Anonymous},
      booktitle={SIGGRAPH Asia},
      year={2025}
    }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website source code is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
